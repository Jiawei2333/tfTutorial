{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "\n",
    "def getNow():\n",
    "    now       = dt.now().strftime('%Y-%m-%d--%H-%M-%S')\n",
    "    nowFolder = os.path.join('./logFolder', now)\n",
    "    return nowFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X = np.random.rand(N, 2)\n",
    "y = 2*X[:, 0] + 3*X[:, 1] + 4 + 0.1*(np.random.rand(N)-0.5)\n",
    "y = y.reshape((-1, 1))\n",
    "tMask = np.random.choice([True, False], (N,), p=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sankhamukherjee/Documents/Tutorial/basic Tensorflow tutorial/env/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('trainData'):\n",
    "    inpTrain = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='inpTrain')\n",
    "    outTrain = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='outTrain')\n",
    "\n",
    "with tf.variable_scope('testData'):\n",
    "    inpTest = tf.placeholder(dtype=tf.float32, shape=(None, 2), name='inpTest')\n",
    "    outTest = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='outTest')\n",
    "\n",
    "with tf.variable_scope('model'):\n",
    "    W = tf.Variable(initial_value=np.random.rand(2, 1), name='W', dtype=tf.float32)\n",
    "    b = tf.Variable(initial_value=0, name='b', dtype=tf.float32)\n",
    "    \n",
    "    # Add summaries \n",
    "    # ---------------------\n",
    "    tf.summary.scalar('bSummary', b)\n",
    "    tf.summary.histogram('WSummary', W)\n",
    "    tf.summary.scalar('WMin', tf.reduce_min(W))\n",
    "    tf.summary.scalar('WMax', tf.reduce_max(W))\n",
    "\n",
    "    with tf.variable_scope('train'):\n",
    "        yHatTrain = tf.matmul(inpTrain,  W )+ b\n",
    "        errTrain  = tf.reduce_mean((outTrain - yHatTrain)**2, name='errTrain')\n",
    "        tf.summary.scalar('trainErr', errTrain)\n",
    "        \n",
    "    with tf.variable_scope('test'):\n",
    "        yHatTest = tf.matmul(inpTest,  W )+ b\n",
    "        errTest  = tf.reduce_mean((outTest - yHatTest)**2, name='errTest')\n",
    "        tf.summary.histogram('testErrHist', (outTest - yHatTest)**2)\n",
    "        tf.summary.scalar('testErr', errTest)\n",
    "\n",
    "with tf.variable_scope('optimizer'):\n",
    "    lr = tf.Variable(0.01, dtype=tf.float32, name='learningRate')\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(errTrain)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 32.92376708984375, Testing: 32.44841384887695\n",
      "Training: 14.910260200500488, Testing: 14.674463272094727\n",
      "Training: 5.778097152709961, Testing: 5.6680121421813965\n",
      "Training: 1.9550249576568604, Testing: 1.9012222290039062\n",
      "Training: 0.6636378169059753, Testing: 0.6317040324211121\n",
      "Training: 0.3111761510372162, Testing: 0.2873738706111908\n",
      "Training: 0.2244434356689453, Testing: 0.20431579649448395\n",
      "Training: 0.19500388205051422, Testing: 0.1773156225681305\n",
      "Training: 0.17522749304771423, Testing: 0.15963959693908691\n",
      "Training: 0.1571352332830429, Testing: 0.14350537955760956\n",
      "Training: 0.13989104330539703, Testing: 0.1280975490808487\n",
      "Training: 0.1235775351524353, Testing: 0.11348500102758408\n",
      "Training: 0.10832385718822479, Testing: 0.09978289157152176\n",
      "Training: 0.09422020614147186, Testing: 0.08707331120967865\n",
      "Training: 0.081316277384758, Testing: 0.07540386915206909\n",
      "Training: 0.06962781399488449, Testing: 0.06479344516992569\n",
      "Training: 0.05914236605167389, Testing: 0.055236417800188065\n",
      "Training: 0.04982489347457886, Testing: 0.046707648783922195\n",
      "Training: 0.04162327200174332, Testing: 0.039167072623968124\n",
      "Training: 0.034472521394491196, Testing: 0.03256283700466156\n",
      "Training: 0.0282986331731081, Testing: 0.02683471515774727\n",
      "Training: 0.02302180603146553, Testing: 0.02191649191081524\n",
      "Training: 0.018559232354164124, Testing: 0.0177384652197361\n",
      "Training: 0.014826999045908451, Testing: 0.014228845946490765\n",
      "Training: 0.011741915717720985, Testing: 0.01131544727832079\n",
      "Training: 0.009223832748830318, Testing: 0.008927833288908005\n",
      "Training: 0.0071953050792217255, Testing: 0.006996946409344673\n",
      "Training: 0.005584076978266239, Testing: 0.005457601044327021\n",
      "Training: 0.00432334141805768, Testing: 0.004248877055943012\n",
      "Training: 0.0033524015452712774, Testing: 0.0033148624934256077\n",
      "Training: 0.002617069287225604, Testing: 0.0026051881723105907\n",
      "Training: 0.002070079790428281, Testing: 0.002075580880045891\n",
      "Training: 0.001670748577453196, Testing: 0.0016876698937267065\n",
      "Training: 0.0013849432580173016, Testing: 0.001409089658409357\n",
      "Training: 0.00118463602848351, Testing: 0.001213107374496758\n",
      "Training: 0.0010473174042999744, Testing: 0.0010781757300719619\n",
      "Training: 0.0009553406853228807, Testing: 0.0009873377857729793\n",
      "Training: 0.0008952216012403369, Testing: 0.0009275877964682877\n",
      "Training: 0.0008569278288632631, Testing: 0.0008892206242308021\n",
      "Training: 0.0008331866702064872, Testing: 0.0008651826647110283\n",
      "Training: 0.00081888388376683, Testing: 0.0008504917495884001\n",
      "Training: 0.000810521945822984, Testing: 0.0008417375502176583\n",
      "Training: 0.0008057830273173749, Testing: 0.0008366424008272588\n",
      "Training: 0.0008031890611164272, Testing: 0.0008337449398823082\n",
      "Training: 0.0008018168155103922, Testing: 0.0008321291534230113\n",
      "Training: 0.0008011174504645169, Testing: 0.000831242767162621\n",
      "Training: 0.0008007737924344838, Testing: 0.0008307608659379184\n",
      "Training: 0.0008006127318367362, Testing: 0.0008304960210807621\n",
      "Training: 0.0008005397394299507, Testing: 0.0008303606882691383\n",
      "Training: 0.000800509296823293, Testing: 0.0008302817586809397\n",
      "Training: 0.0008004955016076565, Testing: 0.0008302321657538414\n",
      "Final Values\n",
      "------------------------------\n",
      "Training: 0.0008004955016076565, Testing: 0.0008302321657538414\n",
      "tensorboard --logdir=./logFolder/2019-05-10--16-29-02\n"
     ]
    }
   ],
   "source": [
    "folder = getNow()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(folder, sess.graph)\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(5001):\n",
    "        sess.run( opt, feed_dict={\n",
    "            inpTrain : X[tMask, :],\n",
    "            outTrain : y[tMask, :],\n",
    "            lr       : 0.01\n",
    "             })\n",
    "        \n",
    "        if (i % 100) == 0:\n",
    "            summary, errTrainVal, errTestVal = sess.run( [merged, errTrain, errTest], feed_dict={\n",
    "                inpTrain : X[tMask, :],\n",
    "                outTrain : y[tMask, :],\n",
    "                inpTest : X[~tMask, :],\n",
    "                outTest : y[~tMask, :]})\n",
    "            \n",
    "            writer.add_summary(summary, i)\n",
    "            print('Training: {}, Testing: {}'.format(errTrainVal, errTestVal))\n",
    "            \n",
    "writer.close()\n",
    "\n",
    "print('Final Values')\n",
    "print('-'*30)\n",
    "print('Training: {}, Testing: {}'.format(errTrainVal, errTestVal))\n",
    "    \n",
    "print('tensorboard --logdir={}'.format( folder ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
